---
title: "Hands-on with hierarchical models for spatial data" 
output: 
  learnr::tutorial:
      progressive: true
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
require(rstanarm)
require(bayesplot)
require(ggplot2)
require(lhs)

source("R/multilevel.R")

knitr::opts_chunk$set(echo = FALSE)
```
## Neighborhoods, wealth, and blood pressure

In this example, imagine individuals are grouped into discrete neighborhoods by wealth (not an unrealistic assumption), and that increasing wealth is also protective against SBP at the individual level

Now, we'll let a factor that is potentially associated with SBP risk, e.g. (walkability, which could decrease SBP; or exposure to pollution which could increase it), vary across neighborhoods, and we're going to look at what happens when we let that factor increase or decrease along with average neighborhood wealth. 

Specifically, we're looking at a kind of classic *multilevel* or *hierarchical* model. Again we're interested in a *continuous* outcome at the individual level, i.e. systolic blood pressure. And we're going to model variation in this outcome as a function of:


1. An individual factor - in this case wealth - represented by the *covariate* $x_i$ and model coefficient $\beta$. We assume that wealth is protective, i.e. as wealth goes up, SBP goes down. So we constrain the value of $\beta \le 0$. 

2. An unobserved attribute of each neighborhood that is associated with either increased or decreased SBP, denoted by the coefficient $\gamma$, which can take on both positive and negative values. To keep things simple, we assume that the intensity of this effect increases from neighborhood 1 to neighborhood 6, just to make things easier to visualize.

### Some assumptions

In this model we're making two more simplifying assumptions which we can relax later on:

1. Individuals sort *deterministically* into neighborhoods by wealth. The population is just sliced up into 6 neighborhoods with the poorest 1/6 of the population in neighborhood 1, and the wealthiest in neighborhood 6, etc. 

2. The effects of living in each neighborhood are also *deterministic*, i.e. there is no randomness associated with the effect of living in Neighborhood 3 vs. Neighborhood 1, for example. This is just to keep things relatively simple for now. 

When we put this all together, we have a model that looks like this:

$y_{ij} = \alpha + \beta x_i + \gamma z_j + \epsilon_i$

In other words, the expected value of SBP for individual $i$ in neighborhood $j$ is a function of her wealth ($x_i$), a condition in her neighborhood of residence ($z_j$) and normally distributed variaton at the individual level ($\epsilon_i$), where $\epsilon_i \sim \text{Normal}(0, \sigma)$ where $\sigma$ is the standard devation of individual SBP outcomes.

Ok, now that we've laid out some of the preliminaries, time to see what this looks like!

### Time to kick the tires!

Go ahead and move the sliders around to see what kinds of patterns you can see. Specifically, what happens if you make the effect of neighborhood and wealth go in the *same* direction? What about different directions? 


```{r}
sidebarPanel(
  
sliderInput("beta_1_n", "Change in SBP for each 1-unit change in individual wealth (smaller values indicate more protective effect of wealth):", min = -3, max = 0, value = 0),
sliderInput("beta_2_n", "Difference in average SBP between neighborhood 1 and neighborhood 6:", min = -10, max = 10, value = 0),
sliderInput("alpha_n", "Intercept:", min = 120, max = 140, value = 130),

)

mainPanel(
 plotOutput("neighborhoodPlot")
)


```
The blue line overlaid on the plot is just a simple linear regression line showing the association between wealth and SBP estimated from these data, while ignoring neighborhood-level effects. Can you mess things up enough so that the direction of the effect indicated by the regression line is *opposite* to the input value? 

### Fitting a model

Now, let's see what this looks like in terms of our regression coefficients. First, what is the impact of having a each successive neighborhood be *more risky* (i.e. $\gamma > 0$) on the estimate of the effect of wealth if you set  wealth to be strongly protective? 

```{r}
sidebarPanel(

checkboxInput("n_adjust", "Adjust for neighborhood:", FALSE)

)

mainPanel(
  verbatimTextOutput("n_model_summary")
)

```

```{r, context = "server"}
group_indices <- function(N, J) {
    out_groups <- c()
    split_size <- N %/% J

    for (i in 1:(J - 1)) {
        out_groups <- c(out_groups, rep(i, split_size))
    }

    if ((N %% split_size) > 0) {
        last_indices <- rep(J, N %% split_size)
    } else {
        last_indices <- rep(J, split_size)
    }
    out_groups <- c(out_groups, last_indices)

    return(out_groups)
}



area_data <- reactive({
  
J <- 5
N <- 1000

xvals <- 10 * sort(as.vector(randomLHS(N, 1)))
group_ids <- group_indices(N, J)
walkability <- (group_ids - 1) / (J - 1)

y_hat <- input$alpha_n + input$beta_1_n * xvals + input$beta_2_n * walkability

y_sim <- rnorm(length(y_hat), y_hat, 2)

df <- data.frame(x = xvals, walkability = walkability, neighborhood = as.factor(group_ids), y = y_sim)

return(df)

})

output$neighborhoodPlot <- renderPlot({
g <- ggplot(area_data(), aes(x = x, y = y)) +
    geom_point(aes(colour = neighborhood)) +
    xlab("Wealth") +
    ylab("SBP")
    
    if (input$n_adjust == TRUE) {
      g <- g+ geom_smooth(method = "lm", aes(group = neighborhood), se = FALSE) 
    } else {
      g <- g + geom_smooth(method = "lm", se = FALSE) 
    }


return(g)
})

 n_model_fit <- reactive({
    if (input$n_adjust == TRUE) {
      fit <- lm(y ~ x + neighborhood , data = area_data())
             names(fit$coefficients) <- c("Intercept", "Wealth", "Neighborhood 2", "Neighborhood 3", "Neighborhood 4", "Neighborhood 5")
      
    } else {

     fit <- lm(y ~ x, data = area_data())
       names(fit$coefficients) <- c("Intercept", "Wealth")
    }
    return(fit)
  })
  
  output$n_model_summary <- renderPrint({
    summary(n_model_fit())
  })
```

Finally, tick the box to adjust for neighborhood and see how it impacts the paramter values. This model is just a simple example that treats each neighborhood as its own *categorical variable* since there are only a few of them. But this model has most of the ingredients of a classic hierarchical model. 

Next, we'll take a look at what this problem looks like in a slightly more complex context where:

1. We allow there to be more *random variation* in the effect of living in a given place *and*
2. There are more than just a few units so that we need to use a model that can accomodate this added complexity.

## Adding neighborhood-level variability

Now, let's add more neighborhoods to this example, and introduce both *systematic* and *random variation* at the neighborhood level in addition to the individual level. In this example we consider observations from 1000 people sampled randomly from 30 neighborhoods, more than can be easily dealt with in a normal regression model.

1. Just like in the previous example, we'll model individual-level outcomes as a function of *systematic* and *random* variation. In this case, systematic variation will be represented by the coefficient $\beta$, which represents the relationship between individual wealth and SBP, and normally-distributed random variation by the error term $\epsilon_i$. In other words $\epsilon_i \sim \text{Normal}(0, \sigma_i)$, where $\sigma_i$ is the standard deviation of SBP values *between individuals*.

2. In addition to this, we're going to allow each neighborhood $j$ to have a mean SBP that deviates from the population mean SBP. This is represented by a *neighborhood-level* error term, which we'll call $\epsilon_j$. This value represents how far the mean value of the systolic blood pressure (SBP) outcome for individuals living in neighborhood $j$ is from the population intercept $\alpha$. Similarly to the individual-level error term, this is normally distributed, i.e. $\epsilon_j \sim \text{Normal}(0, \sigma_j)$, where $\epsilon_j$ is the deviation of the mean SBP in neighborhood $j$ from the average neighborhood-level mean across all neighborhoods. In other words, this represents *between-neighborhood* variation.

### Generate neighborhood data

The first thing we're going to do is to simulate values of the neighborhood-level mean SBP. There are two components underlying variability in this example:

1. *Systematic* variation due to difference in the walkability and physical environment of each neighborhood. This represents the idea that people living in neighborhoods that are more walkable may get more hours of exercise each week, contributing to their overall health and lowering the average SBP of people living in that neighborhood. 

2. *Random* variation due to other unobserved neighborhood-level factors. This is all the stuff not in our model: When $sigma_j$ is small, we assume that most of the variability between neighborhoods is due to *systematic*, observed factors, or perhaps that there isn't much variability at all. 

In this example, walkability is represented as a *z-score*, i.e. in terms of standard deviations above or below the mean walkability of all neighborhoods.

```{r}
histogramUI("hist1")
```


### Generate individual data

Now that we have simulated a set of neighborhood level means, let's simulate the individual data we're going to be working with. 

In addition to neighborhood features like walkability, other individual-level attributes are likely to impact SBP. For example, people with higher incomes may be more able to access quality care, avoid stressful work environments, etc.,  which may make them more likely to have lower SBP. 

To begin, we'll assume that there is no relationship between income and walkability, i.e. a neighborhood with a low average income is just as likely to be walkable as one with a high average income. Once again, income values are expressed as a z-score, with values indicating standard deviations above or below the mean income across all neighborhoods.

Try moving the slider to vary the protective effect of income on SBP to get a sense of what the final dataset looks like. Here, the colors of the points represent the walkability of the neighborhoods that individuals live in.


```{r}
individualUI("hist1")
```

### Model the data

In this section, we'll look at the impact of *omitting variables* from our regression model on the conclusions we get from it. Here, imagine we are conducting a study looking just at the relationship between individual income and SBP, and we have no information on the individual neighborhoods people live in. Take a look at what happens when you estimate the effect of income on SBP with and without walkability in the model, and using a regular linear regression model (the `lm` function in R) or a hierarchical regression model that accounts for neighborhood-level *clustering* of risk. 

```{r}
modelUI("hist1")
```

Take a look at the different panels, which show 1) the model results, 2) the distribution of the model *residuals* as compared to a normal distribution (known as a [Q-Q plot](https://en.wikipedia.org/wiki/Q%E2%80%93Q_plot)), and 3) a plot of the model residuals plotted against our variable of interest, income. 

#### Questions

1. Under what conditions do you get an over-estimate of the protective impact of income on SBP?
2. Does adjusting for walkability without accounting for neighborhood *clustering* get better results? When does it not work to do this?
3. Are there situations in which adjusting for neighborhood clustering does not bring about the appropriate values of the input values?

### Try to break the model!

Now, we're going to try to see what happens when we add some more complexity. Up until this point, we've assumed that neighborhood wealth and walkability are unrelated. Obviously this doesn't square with our experiences of the real world, in which certain desirable attributes, such as walkability, lead to an increase in prices and the average wealth of people living there.

Use the slider below to change this relationship by increasing the correlation between neighborhood level average income and and neighborhood level walkability. Also go back up to the other sections and try to change other input settings and see what factors impact your ability to get good estimates and to fulfill the requirements of a linear regression model (i.e. normal, uncorrelated residuals).

```{r}
correlationUI("hist1")
```

```{r, context="server"}
histogramServer("hist1")

```